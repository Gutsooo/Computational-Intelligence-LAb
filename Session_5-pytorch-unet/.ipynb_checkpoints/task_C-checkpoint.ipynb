{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "th0Sz8xE02tq"
   },
   "source": [
    "## Task C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1kAlycorxXk"
   },
   "source": [
    "### U-net\n",
    "U-Net was first proposed for Biomedical Image Segmentation. One of the main advantages of using U-Net is its ability to yield relatively good results on pixel-labelling tasks with limited dataset images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvLPuyMssE7j"
   },
   "source": [
    "### Image segmentation\n",
    "This task focuses on the task of image segmentation, using a modified U-Net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOV3AtqdsMLe"
   },
   "source": [
    "### What is image segmentation?\n",
    "So far you have seen image classification, where the task of the network is to assign a label or class to an input image. However, suppose you want to know where an object is located in the image, the shape of that object, which pixel belongs to which object, etc. In this case you will want to segment the image, i.e., each pixel of the image is given a label. Thus, the task of image segmentation is to train a neural network to output a pixel-wise mask of the image. This helps in understanding the image at a much lower level, i.e., the pixel level. Image segmentation has many applications in medical imaging, self-driving cars and satellite imaging to name a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Lk7T8leI3BZR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as transform\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11wtbsFKtFtN"
   },
   "source": [
    "### 1.1 loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "obj9wst7sVQg"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dir \u001b[38;5;241m=\u001b[39m \u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# train dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m val_dir \u001b[38;5;241m=\u001b[39m glob(\u001b[38;5;28;01mNone\u001b[39;00m)   \u001b[38;5;66;03m# validation dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dir), \u001b[38;5;28mlen\u001b[39m(val_dir))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/glob.py:22\u001b[0m, in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mglob\u001b[39m(pathname, \u001b[38;5;241m*\u001b[39m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of paths matching a pathname pattern.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    The pattern may contain simple shell-style wildcards a la\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    zero or more directories and subdirectories.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/glob.py:43\u001b[0m, in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iglob\u001b[39m(pathname, recursive, dironly):\n\u001b[0;32m---> 43\u001b[0m     dirname, basename \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pathname):\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dironly\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/posixpath.py:103\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(p):\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Split a pathname.  Returns tuple \"(head, tail)\" where \"tail\" is\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    everything after the final slash.  Either part may be empty.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     sep \u001b[38;5;241m=\u001b[39m _get_sep(p)\n\u001b[1;32m    105\u001b[0m     i \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mrfind(sep) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "train_dir = glob(None) # train dataset\n",
    "val_dir = glob(None)   # validation dataset\n",
    "\n",
    "print(len(train_dir), len(val_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VECyGW8otQkB"
   },
   "source": [
    "### 1.2 showing a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MbNo6q4ta4W"
   },
   "outputs": [],
   "source": [
    "sample_image_fp = os.path.join(train_dir[0])\n",
    "sample_image = Image.open(sample_image_fp).convert(\"RGB\")\n",
    "plt.imshow(sample_image)\n",
    "print(sample_image_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGxawqBguBjF"
   },
   "source": [
    "### 2. Defining Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKbAa0O8uAwr"
   },
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "validation_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcYadyy2uIfz"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, images_path ,transform_img=None ,transform_label=None):\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.transform_img = transform_img\n",
    "        self.transform_label = transform_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img = plt.imread(self.images_path[idx])\n",
    "        image,label = img[:,:int(img.shape[1]/2)],img[:,int(img.shape[1]/2):]\n",
    "\n",
    "        if self.transform_img:\n",
    "            image = self.transform_img(image)\n",
    "\n",
    "        if self.transform_label:\n",
    "            label = self.transform_label(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peMUYjbYuf8r"
   },
   "source": [
    "###3 Defining the Transfoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTNCWo7U9aDu"
   },
   "outputs": [],
   "source": [
    "mytransformsImage = transform.Compose(\n",
    "    [\n",
    "        transform.ToTensor(),\n",
    "        #transform.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        transforms.RandomHorizontalFlip(p=0.9)\n",
    "    ]\n",
    ")\n",
    "\n",
    "mytransformsLabel = transform.Compose(\n",
    "    [\n",
    "        transform.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXQWeroOv-wO"
   },
   "outputs": [],
   "source": [
    "# train dataset\n",
    "#your code\n",
    "traindata = None\n",
    "# val dataset\n",
    "valdata = None\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFDz3SS390rW"
   },
   "outputs": [],
   "source": [
    "# Creating the DataLoaders\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(traindata,batch_size)\n",
    "vaild_loader = DataLoader(valdata,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WB9nL7huwYd3"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    This is a helper function.\n",
    "    This will help in ploting the masked got from the model.\n",
    "\n",
    "'''\n",
    "def show(img,output,label,denorm = False):\n",
    "    img,output,label = img.cpu(),output.cpu(),label.cpu()\n",
    "    fig,ax = plt.subplots(len(output),3,figsize=(10,10))\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        if(len(output) == 3):\n",
    "            Img,Lab,act = img[i],output[i],label[i]\n",
    "            Img,Lab,act = Img,Lab.detach().permute(1,2,0).numpy(),act\n",
    "            ax[i][0].imshow(Img.permute(1,2,0))\n",
    "            ax[i][1].imshow(Lab)\n",
    "            ax[i][2].imshow(act.permute(1,2,0))\n",
    "        else:\n",
    "            Img,Lab,act = img[i],output[i],label[i]\n",
    "            Img,Lab,act = Img,Lab.detach().permute(1,2,0).numpy(),act\n",
    "            ax[0].imshow(Img.permute(1,2,0))\n",
    "            ax[1].imshow(Lab)\n",
    "            ax[2].imshow(act.permute(1,2,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBcz9kyUwZNG"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8cXmhXjwoFB"
   },
   "source": [
    "###4. Building UNet Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q26484XxBx_"
   },
   "source": [
    "### 4.1\n",
    "This Module representes the individual horizontal conv block layers in the Unet Model. And you need to do the following steps.\n",
    "* 1-Conv()\n",
    "* 2-BatchNorm()\n",
    "* 3- ReLU()\n",
    "* 4-Conv()\n",
    "* 5-ReLU()\n",
    "kernel size = 3 padding = 1 stride = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWziEdxpyt0a"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "    This Module representes the individual horizontal conv block layers in the Unet Model.\n",
    "    Conv() -> BatchNorm() -> ReLU() -> Conv() -> ReLU()\n",
    "\n",
    "'''\n",
    "\n",
    "class Convblock(nn.Module):\n",
    "\n",
    "      def __init__(self,input_channel,output_channel,kernal=3,stride=1,padding=1):\n",
    "\n",
    "        super().__init__()\n",
    "        self.convblock = nn.Sequential(\n",
    "            #your code\n",
    "            None\n",
    "            None\n",
    "            None\n",
    "            None\n",
    "            None\n",
    "            #end\n",
    "        )\n",
    "\n",
    "\n",
    "      def forward(self,x):\n",
    "        #your code\n",
    "        x = None\n",
    "        #end\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXcJJ61Qz3LW"
   },
   "source": [
    "### 4.2\n",
    "Write the appropriate code instead of the parts where the 'None' is placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4rbNlia-h8v"
   },
   "outputs": [],
   "source": [
    "# Encoder -> BottelNeck => Decoder\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self,input_channel,retain=True):\n",
    "\n",
    "        super().__init__()\n",
    "        #encoder\n",
    "        self.conv1 = None  #input\n",
    "        self.conv2 = None          #first block 32\n",
    "        self.conv3 = None          #block two 64\n",
    "        self.conv4 = None          #block three 128\n",
    "\n",
    "\n",
    "        # neck\n",
    "\n",
    "        self.neck=None          #neck 256 kernet_size=3 stride=1 use conv2d\n",
    "\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(512,256,3,2,0,1)\n",
    "\n",
    "        self.dconv4 = None  #conveblock\n",
    "        self.upconv3 = nn.ConvTranspose2d(256,128,3,2,0,1)\n",
    "        self.dconv3 = None #conveblock\n",
    "        self.upconv2 = nn.ConvTranspose2d(128,64,3,2,0,1)\n",
    "        self.dconv2 = None #conveblock\n",
    "        self.upconv1 = nn.ConvTranspose2d(64,32,3,2,0,1)\n",
    "        self.dconv1 = None #conveblock\n",
    "        self.out = nn.Conv2d(32,3,1,1)\n",
    "        self.retain = retain\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        # Encoder Network\n",
    "\n",
    "        # Conv down 1\n",
    "        conv1 = None\n",
    "        pool1 = None    #kerner_size =2 stride=2\n",
    "        # Conv down 2\n",
    "        conv2 = None\n",
    "        pool2 = None    #kerner_size =2 stride=2\n",
    "        # Conv down 3\n",
    "        conv3 = None\n",
    "        pool3 = None    #kerner_size =2 stride=2\n",
    "        # Conv down 4\n",
    "        conv4 = None\n",
    "        pool4 = None    #kerner_size =2 stride=2\n",
    "\n",
    "        # BottelNeck\n",
    "        neck = None\n",
    "\n",
    "        # Decoder Network\n",
    "\n",
    "        # Upconv 1\n",
    "        upconv4 = None\n",
    "        croped = self.crop(conv4,upconv4)\n",
    "        # Making the skip connection 1\n",
    "        dconv4 = None\n",
    "        # Upconv 2\n",
    "        upconv3 = None\n",
    "        croped = self.crop(conv3,upconv3)\n",
    "        # Making the skip connection 2\n",
    "        dconv3 = None\n",
    "        # Upconv 3\n",
    "        upconv2 = None\n",
    "        croped = self.crop(conv2,upconv2)\n",
    "        # Making the skip connection 3\n",
    "        dconv2 = None\n",
    "        # Upconv 4\n",
    "        upconv1 = None\n",
    "        croped = self.crop(conv1,upconv1)\n",
    "        # Making the skip connection 4\n",
    "        dconv1 = None\n",
    "        # Output Layer\n",
    "        out = self.out(None)\n",
    "\n",
    "        if self.retain == True:\n",
    "            out = F.interpolate(out,list(x.shape)[2:])\n",
    "\n",
    "        return out\n",
    "\n",
    "    def crop(self,input_tensor,target_tensor):\n",
    "        # For making the size of the encoder conv layer and the decoder Conv layer same\n",
    "        _,_,H,W = target_tensor.shape\n",
    "        return transform.CenterCrop([H,W])(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkK0BcqXM0kq"
   },
   "source": [
    "### 5. Initializing the model\n",
    "* lr = 0.01\n",
    "* epoch = 30\n",
    "* loss function = MSE\n",
    "* optimizer = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhJGUXND-qIH"
   },
   "outputs": [],
   "source": [
    "# initializing the model\n",
    "model = UNet(3).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jp08pQjNUo-"
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rja4IAbbNGCt"
   },
   "outputs": [],
   "source": [
    "# Choosing the loss function to be Mean Square Error Loss\n",
    "lossfunc = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OOBpASiMxTb"
   },
   "source": [
    "### 6. training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422,
     "referenced_widgets": [
      "4038789813bf475a9137faf7c1422aa3",
      "61ea5d23d9f444d888dd04468cf424b0",
      "82b8e67f062c4ee78541f7025eed8230",
      "bdc807eb6c4143dabad32706ba7a4ba2",
      "f9406c1c3af44c4bba54b338d4cb52a6",
      "a8043f3645f04fe69b18cd2dae6a8234",
      "dcdf22dece9048c39b9020e3c7729fbb",
      "0fd3708770bb40c8b5dbd7a51c3d03f5",
      "d8e5400543e848879065144edce86973",
      "fd07494cd3ae455ab85e0b2a75b47514",
      "5df4b1d6c8aa439e81540f05908a5550"
     ]
    },
    "id": "AMfWi3Nk-2lB",
    "outputId": "e32d8148-4ac9-43ec-9ef7-89426a32e9f3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4038789813bf475a9137faf7c1422aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a533821009ed>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         '''\n\u001b[1;32m      8\u001b[0m             \u001b[0mTraning\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-40a5af140549>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2193\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0;34m\"``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m             )\n\u001b[0;32m-> 1563\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1565\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "\n",
    "    trainloss = 0\n",
    "    valloss = 0\n",
    "\n",
    "    for img,label in tqdm(train_loader):\n",
    "        '''\n",
    "            Traning the Model.\n",
    "        '''\n",
    "        optimizer.zero_grad()     #clear gradient for next train\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(img) # predict\n",
    "\n",
    "        loss = lossfunc(label, img) #compute loss\n",
    "        loss.backward()    #backpropagation\n",
    "        optimizer.step()    #apply gradients\n",
    "\n",
    "        trainloss+=loss.item()\n",
    "\n",
    "    if(i%5==0):\n",
    "        show(img,output,label)\n",
    "\n",
    "    train_loss.append(trainloss/len(train_loader))\n",
    "\n",
    "    for img,label in tqdm(vaild_loader):\n",
    "        '''\n",
    "            Validation of Model.\n",
    "        '''\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(img)\n",
    "        loss = lossfunc(output,label)\n",
    "        valloss+=loss.item()\n",
    "\n",
    "    val_loss.append(valloss/len(vaild_loader))\n",
    "\n",
    "    print(\"epoch : {} ,train loss : {} ,valid loss : {} \".format(i,train_loss[-1],val_loss[-1]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
